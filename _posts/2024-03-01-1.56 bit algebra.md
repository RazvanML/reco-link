This week I've looked at the <a href="https://arxiv.org/abs/2402.17764">LLM optimization of using 1.58 bit algebra</a> to speed up the training and transformation.

